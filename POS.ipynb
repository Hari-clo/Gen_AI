{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "POS tagging involves assigning grammatical categories(like nouns, verbs, adverb etc....)\n",
        "CHALLENGES : ambiguity, unknown words , language specific challenges"
      ],
      "metadata": {
        "id": "f41srl5CCiu_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF0sL8i7CZGq"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6913e0ac",
        "outputId": "f23f0f75-3008-4f9b-f115-f491f299af99"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "\n",
        "text=\"The quick brown fox jumps over the lazy dog\"\n",
        "words=word_tokenize(text)\n",
        "pos_tags=nltk.pos_tag(words)\n",
        "print(pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCpmMpk7DmHt",
        "outputId": "492ec281-7688-43e7-f17a-2b1368d8d5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spacy - used for more accuracy"
      ],
      "metadata": {
        "id": "3U_teHEdkpVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "doc=nlp(\"The quick brown fox jumps over the lazy dog\")\n",
        "for token in doc:\n",
        "    print(token.text,token.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th0Vr9idGJ_l",
        "outputId": "a931d447-3326-4f74-fbf1-adf34b55e57c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The DET\n",
            "quick ADJ\n",
            "brown ADJ\n",
            "fox NOUN\n",
            "jumps VERB\n",
            "over ADP\n",
            "the DET\n",
            "lazy ADJ\n",
            "dog NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moderate use not recommended (textblob)\n"
      ],
      "metadata": {
        "id": "-NR1NGhqlFIR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bf55702",
        "outputId": "642d3865-19b4-42aa-e5c5-2d7a72678c44"
      },
      "source": [
        "!python -m textblob.download_corpora"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48e2cfb8",
        "outputId": "2f678fe4-cd02-4436-a33d-74eba9df2d25"
      },
      "source": [
        "import nltk\n",
        "from textblob import TextBlob\n",
        "text=\"The quick brown fox jumps over the lazy dog\"\n",
        "blob=TextBlob(text)\n",
        "for word,pos in blob.tags:\n",
        "    print(word,pos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The DT\n",
            "quick JJ\n",
            "brown NN\n",
            "fox NN\n",
            "jumps VBZ\n",
            "over IN\n",
            "the DT\n",
            "lazy JJ\n",
            "dog NN\n"
          ]
        }
      ]
    }
  ]
}